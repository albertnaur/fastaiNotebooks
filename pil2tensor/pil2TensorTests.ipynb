{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from PIL import *\n",
    "\n",
    "import colorcet as cc\n",
    "cmap_grey = cc.cm.linear_grey_0_100_c0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of  speed and correctness of conversion of PIL Images to tensors\n",
    "\n",
    "The result is that the proposed method \"allPil2tensor\" can handle both rgb and 16bit gray images correct\n",
    "\n",
    "The existing method \"Pil2tensor\" can only handle jpg images/ 8 bit images\n",
    "\n",
    "The proposed method is also slighty faster if we include the following conversion of float that takes place in open_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a test imag\n",
    "arr = np.random.randint(0, 2**8-1, (224, 224, 3), dtype=np.uint8)  # or np.ones etc.\n",
    "img = Image.fromarray(np.asarray(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The pil2tensor methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the existing method\n",
    "def Pil2tensor(image:NPImage)->TensorImage:\n",
    "    \"handles numpy of rgb only - Convert PIL style `image` array to torch style image tensor.\"\n",
    "    arr = ByteTensor(torch.ByteStorage.from_buffer(image.tobytes()))\n",
    "    arr = arr.view(image.size[1], image.size[0], -1)\n",
    "    return arr.permute(2,0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "NDArray = ndarray\n",
    "def pil2tensor_new_argtype(image:Union[NPImage,NDArray], dtype)->TensorImage:\n",
    "    #image: must be a PIL.image or a numpy array. \n",
    "    #       Grayscale (single channel) convert to the shape: 1, heigh, widt\n",
    "    #       rgb converts to a shape of:                      3, width, height\n",
    "    #dtype: pytorch support: np.double, np.float16, np.int64, np.int32, and np.uint8\n",
    "    \"Convert PIL.Image or numpy.ndarray to a torch tensor formattet for input to a neural network.\"\n",
    "    \"Usage 1: pil2tensor(Image.open(\\\"dog.47.jpg\\\").convert(fmt), dtype).div_(scale)\"\n",
    "    \"         where fmt = RGB, L (=8bit for fx masks) or I (= int for fx 16 bit grayscale)\"\n",
    "    \"         where scale = 255 for rgb, 65535 for grayscale\"\n",
    "    \"         if your data are already at the right scale then no .div is required\"\n",
    "    \"Usage 2: if your image is a simple rgb of grayscale the you can do. The following is slightly faster but more risky\"\n",
    "    \"         pil2tensor(Image.open(\\\"dog.47.jpg\\\"), dtype).div_(scale) with scale as above. \"\n",
    "    \"Usage 3: pil2tensor(Image.open(numpy_array,dtype), dtype).div_(scale) if data alredy are in a numpy array\"\n",
    "    a = np.asarray(image)\n",
    "    if a.ndim==2 : a = np.expand_dims(a,2)    \n",
    "    a = np.transpose(a, (1, 0, 2))  #transpose width, height to height,width\n",
    "    a = np.transpose(a, (2, 1, 0))  #move channels to the first positionf\n",
    "    return torch.from_numpy( a.astype(dtype, copy=False) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed of pil2tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 µs ± 8.24 µs per loop (mean ± std. dev. of 20 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 20 Pil2tensor(img).float().div_(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 µs ± 1.93 µs per loop (mean ± std. dev. of 20 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 20 pil2tensor_new_argtype(img,np.float32).div_(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed of reading and conversion with convert(RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04 ms ± 412 µs per loop (mean ± std. dev. of 50 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 50 Pil2tensor(Image.open(\"dog.47.jpg\").convert(\"RGB\")).float().div_(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.94 ms ± 47.2 µs per loop (mean ± std. dev. of 50 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 50 pil2tensor_new_argtype(Image.open(\"dog.47.jpg\").convert(\"RGB\"), np.float32).div_(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed of reading and conversion with NO convert(RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6 ms ± 62.2 µs per loop (mean ± std. dev. of 50 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 50 Pil2tensor(Image.open(\"dog.47.jpg\")).float().div_(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.86 ms ± 43.2 µs per loop (mean ± std. dev. of 50 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 50 pil2tensor_new_argtype(Image.open(\"dog.47.jpg\"), np.float32).div_(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert numpy to tensor assuming that the array is already at the right scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrfloat  = np.random.rand(224,224,3).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.44 µs ± 524 ns per loop (mean ± std. dev. of 50 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r 50 pil2tensor_new_argtype(arrfloat,np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the shape correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the image\n",
    "np.asarray(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pil2tensor(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pil2tensor_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-49a57a7c9f68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpil2tensor_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pil2tensor_new' is not defined"
     ]
    }
   ],
   "source": [
    "pil2tensor_new(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the content correct for rgb image\n",
    "Notice that the pixel values are preserved and the tensors size is correct for both conversion methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbg16 = Image.open(\"gray.jpg\").convert(\"RGB\")\n",
    "rbg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(rbg16)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pil2tensor(rbg16).size())\n",
    "pil2tensor(rbg16).int()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pil2tensor_new_argtype(rbg16, np.int).size())\n",
    "pil2tensor_new_argtype(rbg16,np.int)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Is the the content correct for 16bit grayscale png\n",
    "Notice that Pil2tensor truncates the 16 bit values to 8 bit and that the tensor size i wrong\n",
    "\n",
    "allPil2tensor preserve the pixel values and the tensor size is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im16bit = Image.open(\"gray_16bit.png\").convert(\"I\")\n",
    "im16bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(im16bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Pil2tensor(im16bit).size())\n",
    "Pil2tensor(im16bit).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pil2tensor_new_argtype(im16bit,np.int).size())\n",
    "pil2tensor_new_argtype(im16bit,np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show diferent test images in rgb and grascale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extensions = ('.bmp', '.gif', '.icns', '.ico', '.jpg', '.pgm', '.png', '.tga', '.tif')\n",
    "files      = np.asarray( list( Path.cwd().glob(\"*.*\") ) )\n",
    "files      = files[[f.suffix in extensions for f in files]] \n",
    "\n",
    "ncols = 4\n",
    "nrows = int( math.ceil(len(files)/float(ncols)) )\n",
    "\n",
    "fig,axes = plt.subplots(nrows=nrows, ncols=ncols, figsize = (12,12), dpi=100 )\n",
    "axes     = axes.flatten()\n",
    "for i,f in enumerate(files):\n",
    "    im = np.asarray(Image.open(f).convert(\"RGB\"))\n",
    "    axes[i].imshow(  im )\n",
    "    axes[i].set_title(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=nrows, ncols=ncols, figsize = (12,12), dpi=100 )\n",
    "axes     = axes.flatten()\n",
    "for i,f in enumerate(files):\n",
    "    im = np.asarray(Image.open(f).convert(\"I\")) / 65535.\n",
    "    axes[i].imshow(  im, cmap=cmap_grey )\n",
    "    axes[i].set_title(f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
